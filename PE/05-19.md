## Modelos de probabilidades

### Distribucion Binomial

`X:` num de exitos en n ensayos de Bernoulli.

`X~B(n, p)` donde n es el numero de intentos y p es la probabilidad de exito.

### Distribucion de Poisson

`X:` num de exitos en un intervalo continuo, de tiempo o espacio.

Por ejemplo, cantidad de fallas por dia de un sistema o cantidad de baches por cuadra,
cant de typos en un archivo de texto.

```
p(x) = P(X=x) = ((e^(-位))*(位^x))/x!
```

Si 位 es pequenio la asimetria es grande, si 位 es grande, la asimetria tiende a 0.

## Modelos para variables continuas.

`f(x)` funcion de densidad de probabilidad
`F(x) = P(X >= x)` funcion de distribucion acumulada.

Ya no es mas una probabilidad, ahora medimos concentracion de probabilidad alrrededor de un punto.

```
F(x) = P(X >= x) = (int -inf a x) f(s) ds
```

#### Propiedades de f(x):

- f(x) >= 0
- La integral de -inf a inf de la funcion me tiene que dar 1

Para calcular probabilidades con una variable continua, si o si necesito conocer la funcion
de distribucion acumulada. Para calcular en un intervalo, lo ideal es hacer la diferencia de acumuladas.

### Distribucion normal o campana de gauss

Es una campana simetrica **unimodal**. Su funcion de densidad de probabilidad, esta en la carpeta.

Entre `(mu) +- (sigma)` esta el ~68% de la distribucion.

Entre `(mu) +- 2(sigma)` esta el 95.44% de la distribucion.

Entre `(mu) +- 3(sigma)` esta el 99.74% de la distribucion.

Graficos en carpeta.

La funcion de distribucion normal no tiene primitiva, por eso es complicada de calcular.
Y no puedo hacer tablas porque la variable tiene infinitos valores (mu y sigma).

Entonces se hace una transformacion lineal que nos queda `z = (x-mu) / sigma` entonces `Z~N(0,1)`,
esto se conoce como estandarizacion de la normal.